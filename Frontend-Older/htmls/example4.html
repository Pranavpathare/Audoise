<!DOCTYPE html>
<!--
 Copyright 2020 Google LLC

 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->

<html>
  <head>
    <meta charset="utf-8" />
    <title>RecordRTC over Socket.io</title>

    <meta http-equiv="content-type" content="text/html; charset=utf-8" />

    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/icon?family=Material+Icons"
    />
    <link
      rel="stylesheet"
      href="https://code.getmdl.io/1.3.0/material.indigo-pink.min.css"
    />

    <script src="https://www.WebRTC-Experiment.com/RecordRTC.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/2.3.0/socket.io.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io-stream/0.9.1/socket.io-stream.js"></script>
  </head>

  <body>
    <div style="margin: 20px">
      <h1 style="font-size: 18px">
        Example 4: Speech to Text Transcribe Recognize Call
      </h1>

      <div>
        <button id="start-recording">Start Recording</button>
        <button id="stop-recording">Stop Recording</button>
      </div>

      <h2 style="font-size: 14px">
        Results: data[0].results[0].alternatives[0].transcript
      </h2>
      <textarea id="results" style="width: 800px; height: 300px"></textarea>
    </div>

    <script type="text/javascript">
      const symblEndpoint = "ws://127.0.0.1:8000/ws/splitted";

      const ws = new WebSocket(symblEndpoint);

      ws.onopen = (event) => {
        startRecording.disabled = false;
        ws.send(
          JSON.stringify({
            type: "open",
            token: 15,
          })
        );
      };

      ws.onclose = (event) => {
        console.info("Connection to websocket closed");
      };

      // when the server found results send
      // it back to the client
      const resultpreview = document.getElementById("results");
      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        console.log(data);
      };

      const startRecording = document.getElementById("start-recording");
      const stopRecording = document.getElementById("stop-recording");
      let recordAudio;

      // on start button handler
      startRecording.onclick = function () {
        // recording started
        startRecording.disabled = true;

        // make use of HTML 5/WebRTC, JavaScript getUserMedia()
        // to capture the browser microphone stream
        navigator.getUserMedia(
          {
            audio: true,
          },
          function (stream) {
            recordAudio = RecordRTC(stream, {
              type: "audio",
              mimeType: "audio/webm",
              sampleRate: 44100, // this sampleRate should be the same in your server code

              // MediaStreamRecorder, StereoAudioRecorder, WebAssemblyRecorder
              // CanvasRecorder, GifRecorder, WhammyRecorder
              recorderType: StereoAudioRecorder,

              // Dialogflow / STT requires mono audio
              numberOfAudioChannels: 1,

              // get intervals based blobs
              // value in milliseconds
              // as you might not want to make detect calls every seconds
              timeSlice: 4000,

              // only for audio track
              // audioBitsPerSecond: 128000,

              // used by StereoAudioRecorder
              // the range 22050 to 96000.
              // let us force 16khz recording:
              desiredSampRate: 16000,
            });

            recordAudio.startRecording();
            stopRecording.disabled = false;
          },
          function (error) {
            console.error(JSON.stringify(error));
          }
        );
      };

      // on stop button handler
      stopRecording.onclick = function () {
        // recording stopped
        startRecording.disabled = false;
        stopRecording.disabled = true;

        // stop audio recorder
        recordAudio.stopRecording(function () {
          // after stopping the audio, get the audio data
          recordAudio.getDataURL(function (audioDataURL) {
            var files = {
              audio: {
                type: recordAudio.getBlob().type || "audio/wav",
                dataURL: audioDataURL,
              },
            };
            // submit the audio file to the server
            if (ws.readyState === WebSocket.OPEN) {
              console.log(files);
              ws.send(files.audio.dataURL);
            }
          });
        });
      };
    </script>
  </body>
</html>
